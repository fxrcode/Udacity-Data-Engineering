{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "source": [
    "# ETL notebook version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "import os\n",
    "import configparser\n",
    "import logging\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s %(levelname)s  [%(name)s] %(message)s')\n",
    "LOG = logging.getLogger('etl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make sure that your AWS credentials are loaded as env vars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = configparser.ConfigParser()\n",
    "\n",
    "#Normally this file should be in ~/.aws/credentials\n",
    "config.read_file(open('dl.cfg'))\n",
    "\n",
    "os.environ[\"AWS_ACCESS_KEY_ID\"]= config['AWS']['AWS_ACCESS_KEY_ID']\n",
    "os.environ[\"AWS_SECRET_ACCESS_KEY\"]= config['AWS']['AWS_SECRET_ACCESS_KEY']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create spark session with hadoop-aws package\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder\\\n",
    "                     .config(\"spark.jars.packages\",\"org.apache.hadoop:hadoop-aws:2.7.0\")\\\n",
    "                     .getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data from local or S3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Process song_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-09-23 14:13:59,905 INFO  [etl] Here you go, song_data: /home/fxrc/Learn/UdacityNanodegree/Udacity-Data-Engineering/Data-Lake-Spark/data/song_data/*/*/*/*.json\n"
     ]
    }
   ],
   "source": [
    "# get filepath to song data file\n",
    "CWD = os.getcwd()\n",
    "# local data, output_data directory\n",
    "input_data = f\"{CWD}/data/\"\n",
    "output_data = f\"{CWD}/output_data/\"\n",
    "\n",
    "song_data = f\"{input_data}song_data/*/*/*/*.json\"\n",
    "LOG.info(f\"Here you go, song_data: {song_data}\")\n",
    "\n",
    "# read all song json files into df\n",
    "df_s = spark.read.json(song_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-09-23 14:14:01,347 INFO  [etl] df_s count: 71\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- artist_id: string (nullable = true)\n",
      " |-- artist_latitude: double (nullable = true)\n",
      " |-- artist_location: string (nullable = true)\n",
      " |-- artist_longitude: double (nullable = true)\n",
      " |-- artist_name: string (nullable = true)\n",
      " |-- duration: double (nullable = true)\n",
      " |-- num_songs: long (nullable = true)\n",
      " |-- song_id: string (nullable = true)\n",
      " |-- title: string (nullable = true)\n",
      " |-- year: long (nullable = true)\n",
      "\n",
      "+------------------+---------------+-----------------+----------------+--------------------+---------+---------+------------------+--------------------+----+\n",
      "|         artist_id|artist_latitude|  artist_location|artist_longitude|         artist_name| duration|num_songs|           song_id|               title|year|\n",
      "+------------------+---------------+-----------------+----------------+--------------------+---------+---------+------------------+--------------------+----+\n",
      "|ARDR4AC1187FB371A1|           null|                 |            null|Montserrat Caball...|511.16363|        1|SOBAYLL12A8C138AF9|Sono andati? Fing...|   0|\n",
      "|AREBBGV1187FB523D2|           null|      Houston, TX|            null|Mike Jones (Featu...|173.66159|        1|SOOLYAZ12A6701F4A6|Laws Patrolling (...|   0|\n",
      "|ARMAC4T1187FB3FA4C|       40.82624|Morris Plains, NJ|       -74.47995|The Dillinger Esc...|207.77751|        1|SOBBUGU12A8C13E95D|Setting Fire to S...|2004|\n",
      "|ARPBNLO1187FB3D52F|       40.71455|     New York, NY|       -74.00712|            Tiny Tim| 43.36281|        1|SOAOIBZ12AB01815BE|I Hold Your Hand ...|2000|\n",
      "|ARDNS031187B9924F0|       32.67828|          Georgia|       -83.22295|          Tim Wilson|186.48771|        1|SONYPOM12A8C13B2D7|I Think My Wife I...|2005|\n",
      "+------------------+---------------+-----------------+----------------+--------------------+---------+---------+------------------+--------------------+----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# quick inspect\n",
    "LOG.info(f\"df_s count: {df_s.count()}\")\n",
    "df_s.printSchema()\n",
    "df_s.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/fxrc/Learn/UdacityNanodegree/Udacity-Data-Engineering/Data-Lake-Spark\n",
      "71\n"
     ]
    }
   ],
   "source": [
    "# easy local env double check\n",
    "!pwd\n",
    "!find ./data/song_data -name '*.json' -type f | wc -l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Creates or replaces a local temporary view with this DataFrame, so as to use pyspark.sql\n",
    "df_s.createOrReplaceTempView(\"song_view\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- song_id: string (nullable = true)\n",
      " |-- title: string (nullable = true)\n",
      " |-- artist_id: string (nullable = true)\n",
      " |-- year: long (nullable = true)\n",
      " |-- duration: double (nullable = true)\n",
      "\n",
      "+------------------+--------------------+------------------+----+---------+\n",
      "|           song_id|               title|         artist_id|year| duration|\n",
      "+------------------+--------------------+------------------+----+---------+\n",
      "|SOGNCJP12A58A80271|Do You Finally Ne...|ARB29H41187B98F0EF|1972|342.56934|\n",
      "|SOOJPRH12A8C141995|   Loaded Like A Gun|ARBGXIG122988F409D|   0|173.19138|\n",
      "|SOFCHDR12AB01866EF|         Living Hell|AREVWGE1187B9B890A|   0|282.43546|\n",
      "|SOWTBJW12AC468AC6E|Broken-Down Merry...|ARQGYP71187FB44566|   0|151.84934|\n",
      "|SOGOSOV12AF72A285E|   ¿Dónde va Chichi?|ARGUVEV1187B98BA17|1997|313.12934|\n",
      "+------------------+--------------------+------------------+----+---------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-09-23 14:22:15,728 INFO  [etl] songs_table count: 71\n"
     ]
    }
   ],
   "source": [
    "# extract columns to create songs table\n",
    "songs_table = spark.sql(\"\"\"\n",
    "SELECT DISTINCT song_id,\n",
    "                title,\n",
    "                artist_id,\n",
    "                year,\n",
    "                duration\n",
    "FROM song_view  \n",
    "\"\"\")\n",
    "songs_table.printSchema()\n",
    "songs_table.show(5)\n",
    "LOG.info(f\"songs_table count: {songs_table.count()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write songs table to parquet files partitioned by year and artist\n",
    "songs_table.write.partitionBy(\"year\", \"artist_id\").parquet(path=output_data+'songs.parquet', mode=\"overwrite\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- year: long (nullable = true)\n",
      " |-- count(1): long (nullable = false)\n",
      "\n",
      "+----+--------+\n",
      "|year|count(1)|\n",
      "+----+--------+\n",
      "|0   |43      |\n",
      "|2004|4       |\n",
      "|1997|2       |\n",
      "|2003|2       |\n",
      "|1994|2       |\n",
      "|2005|2       |\n",
      "|2000|2       |\n",
      "|2007|1       |\n",
      "|1986|1       |\n",
      "|1969|1       |\n",
      "|1987|1       |\n",
      "|1972|1       |\n",
      "|1964|1       |\n",
      "|1982|1       |\n",
      "|1992|1       |\n",
      "|1999|1       |\n",
      "|1985|1       |\n",
      "|1984|1       |\n",
      "|2008|1       |\n",
      "|1993|1       |\n",
      "+----+--------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "yc = spark.sql(\"\"\"\n",
    "-- select distinct song_id from song_table\n",
    "select year, count(*) from song_table \n",
    "group by 1 \n",
    "order by 2 desc\n",
    "\"\"\")\n",
    "yc.printSchema()\n",
    "yc.show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- artist_id: string (nullable = true)\n",
      " |-- artist_name: string (nullable = true)\n",
      " |-- artist_location: string (nullable = true)\n",
      " |-- artist_latitude: double (nullable = true)\n",
      " |-- artist_longitude: double (nullable = true)\n",
      "\n",
      "+------------------+--------------------+--------------------+---------------+----------------+\n",
      "|         artist_id|         artist_name|     artist_location|artist_latitude|artist_longitude|\n",
      "+------------------+--------------------+--------------------+---------------+----------------+\n",
      "|ARPBNLO1187FB3D52F|            Tiny Tim|        New York, NY|       40.71455|       -74.00712|\n",
      "|ARBEBBY1187B9B43DB|           Tom Petty|     Gainesville, FL|           null|            null|\n",
      "|AR0IAWL1187B9A96D0|        Danilo Perez|              Panama|         8.4177|       -80.11278|\n",
      "|ARMBR4Y1187B9990EB|        David Martin|     California - SF|       37.77916|      -122.42005|\n",
      "|ARD0S291187B9B7BF5|             Rated R|                Ohio|           null|            null|\n",
      "|AR0RCMP1187FB3F427|    Billie Jo Spears|        Beaumont, TX|       30.08615|       -94.10158|\n",
      "|ARKRRTF1187B9984DA|    Sonora Santanera|                    |           null|            null|\n",
      "|ARHHO3O1187B989413|           Bob Azzam|                    |           null|            null|\n",
      "|ARJIE2Y1187B994AB7|         Line Renaud|                    |           null|            null|\n",
      "|ARGIWFO1187B9B55B7|      Five Bolt Main|                    |           null|            null|\n",
      "|AROUOZZ1187B9ABE51|         Willie Bobo|New York, NY [Spa...|       40.79195|       -73.94512|\n",
      "|ARDR4AC1187FB371A1|Montserrat Caball...|                    |           null|            null|\n",
      "|AR47JEX1187B995D81|        SUE THOMPSON|          Nevada, MO|       37.83721|       -94.35868|\n",
      "|ARYKCQI1187FB3B18F|               Tesla|                    |           null|            null|\n",
      "|ARL7K851187B99ACD2|           Andy Andy|                    |           null|            null|\n",
      "|ARNPAGP1241B9C7FD4|           lextrical|                    |           null|            null|\n",
      "|ARXR32B1187FB57099|                 Gob|                    |           null|            null|\n",
      "|ARQ9BO41187FB5CF1F|          John Davis|        Pennsylvania|       40.99471|       -77.60454|\n",
      "|AR1ZHYZ1187FB3C717|       Faiz Ali Faiz|                    |           null|            null|\n",
      "|ARMAC4T1187FB3FA4C|The Dillinger Esc...|   Morris Plains, NJ|       40.82624|       -74.47995|\n",
      "+------------------+--------------------+--------------------+---------------+----------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-09-23 14:21:52,592 INFO  [etl] artists_table count: 69\n"
     ]
    }
   ],
   "source": [
    "# extract columns to create artists table\n",
    "df_s.createOrReplaceTempView(\"song_view\")\n",
    "artists_table = spark.sql(\"\"\"\n",
    "SELECT DISTINCT artist_id, \n",
    "                artist_name, \n",
    "                artist_location, \n",
    "                artist_latitude, \n",
    "                artist_longitude\n",
    "FROM song_view\n",
    "\"\"\")\n",
    "artists_table.printSchema()\n",
    "artists_table.show()\n",
    "LOG.info(f\"artists_table count: {artists_table.count()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- year: long (nullable = true)\n",
      " |-- artist_id: string (nullable = true)\n",
      " |-- count(1): long (nullable = false)\n",
      "\n",
      "+----+------------------+--------+\n",
      "|year|artist_id         |count(1)|\n",
      "+----+------------------+--------+\n",
      "|0   |ARD7TVE1187B99BFB1|2       |\n",
      "|0   |ARNTLGG11E2835DDB9|2       |\n",
      "|0   |ARNPAGP1241B9C7FD4|1       |\n",
      "|0   |ARPFHN61187FB575F6|1       |\n",
      "|1987|ARD842G1187B997376|1       |\n",
      "|2003|AR0IAWL1187B9A96D0|1       |\n",
      "|0   |ARI2JSK1187FB496EF|1       |\n",
      "|0   |AR36F9J1187FB406F1|1       |\n",
      "|0   |ARMBR4Y1187B9990EB|1       |\n",
      "|1984|AR8ZCNI1187B9A069B|1       |\n",
      "|0   |ARKULSX1187FB45F84|1       |\n",
      "|0   |ARGSJW91187B9B1D6B|1       |\n",
      "|0   |ARIG6O41187B988BDD|1       |\n",
      "|1969|ARMJAGH1187FB546F3|1       |\n",
      "|2004|ARVBRGZ1187FB4675A|1       |\n",
      "|0   |AROGWRA122988FEE45|1       |\n",
      "|0   |ARKRRTF1187B9984DA|1       |\n",
      "|0   |AR9AWNF1187B9AB0B4|1       |\n",
      "|2004|ARP6N5A1187B99D1A3|1       |\n",
      "|2004|ARYKCQI1187FB3B18F|1       |\n",
      "+----+------------------+--------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ac = spark.sql(\"\"\"\n",
    "-- select distinct artist_id from song_table\n",
    "select year, artist_id, count(*) from song_table \n",
    "group by 1,2 \n",
    "order by 3 desc\n",
    "\"\"\")\n",
    "ac.printSchema()\n",
    "ac.show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write artists table to parquet files\n",
    "artists_table.write.parquet(output_data+'artists.parquest', mode=\"overwrite\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Process log_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-09-23 14:50:21,032 INFO  [etl] Here you go, log_data: /home/fxrc/Learn/UdacityNanodegree/Udacity-Data-Engineering/Data-Lake-Spark/data/log_data/*.json\n"
     ]
    }
   ],
   "source": [
    "# path log_data\n",
    "# log_data = f\"{input_data}log_data/*/*/*.json\"\n",
    "log_data = f\"{input_data}log_data/*.json\"\n",
    "LOG.info(f\"Here you go, log_data: {log_data}\")\n",
    "\n",
    "# read all song json files into df\n",
    "df_l = spark.read.json(log_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-09-23 14:50:22,597 INFO  [etl] df_l count: 8056\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- artist: string (nullable = true)\n",
      " |-- auth: string (nullable = true)\n",
      " |-- firstName: string (nullable = true)\n",
      " |-- gender: string (nullable = true)\n",
      " |-- itemInSession: long (nullable = true)\n",
      " |-- lastName: string (nullable = true)\n",
      " |-- length: double (nullable = true)\n",
      " |-- level: string (nullable = true)\n",
      " |-- location: string (nullable = true)\n",
      " |-- method: string (nullable = true)\n",
      " |-- page: string (nullable = true)\n",
      " |-- registration: double (nullable = true)\n",
      " |-- sessionId: long (nullable = true)\n",
      " |-- song: string (nullable = true)\n",
      " |-- status: long (nullable = true)\n",
      " |-- ts: long (nullable = true)\n",
      " |-- userAgent: string (nullable = true)\n",
      " |-- userId: string (nullable = true)\n",
      "\n",
      "+-----------+---------+---------+------+-------------+--------+---------+-----+--------------------+------+--------+-----------------+---------+---------------+------+-------------+--------------------+------+\n",
      "|     artist|     auth|firstName|gender|itemInSession|lastName|   length|level|            location|method|    page|     registration|sessionId|           song|status|           ts|           userAgent|userId|\n",
      "+-----------+---------+---------+------+-------------+--------+---------+-----+--------------------+------+--------+-----------------+---------+---------------+------+-------------+--------------------+------+\n",
      "|   Harmonia|Logged In|     Ryan|     M|            0|   Smith|655.77751| free|San Jose-Sunnyval...|   PUT|NextSong|1.541016707796E12|      583|  Sehr kosmisch|   200|1542241826796|\"Mozilla/5.0 (X11...|    26|\n",
      "|The Prodigy|Logged In|     Ryan|     M|            1|   Smith|260.07465| free|San Jose-Sunnyval...|   PUT|NextSong|1.541016707796E12|      583|The Big Gundown|   200|1542242481796|\"Mozilla/5.0 (X11...|    26|\n",
      "|      Train|Logged In|     Ryan|     M|            2|   Smith|205.45261| free|San Jose-Sunnyval...|   PUT|NextSong|1.541016707796E12|      583|       Marry Me|   200|1542242741796|\"Mozilla/5.0 (X11...|    26|\n",
      "|       null|Logged In|    Wyatt|     M|            0|   Scott|     null| free|Eureka-Arcata-For...|   GET|    Home|1.540872073796E12|      563|           null|   200|1542247071796|Mozilla/5.0 (Wind...|     9|\n",
      "|       null|Logged In|   Austin|     M|            0| Rosales|     null| free|New York-Newark-J...|   GET|    Home|1.541059521796E12|      521|           null|   200|1542252577796|Mozilla/5.0 (Wind...|    12|\n",
      "+-----------+---------+---------+------+-------------+--------+---------+-----+--------------------+------+--------+-----------------+---------+---------------+------+-------------+--------------------+------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# quick inspect\n",
    "LOG.info(f\"df_l count: {df_l.count()}\")\n",
    "df_l.printSchema()\n",
    "df_l.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## users table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter by actions for song plays\n",
    "df_l = df_l.filter(df_l.page == 'NextSong')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- user_id: string (nullable = true)\n",
      " |-- first_name: string (nullable = true)\n",
      " |-- last_name: string (nullable = true)\n",
      " |-- gender: string (nullable = true)\n",
      " |-- level: string (nullable = true)\n",
      "\n",
      "+-------+----------+---------+------+-----+\n",
      "|user_id|first_name|last_name|gender|level|\n",
      "+-------+----------+---------+------+-----+\n",
      "|     98|    Jordyn|   Powell|     F| free|\n",
      "|     34|    Evelin|    Ayala|     F| free|\n",
      "|     85|   Kinsley|    Young|     F| paid|\n",
      "|     38|    Gianna|    Jones|     F| free|\n",
      "|     85|   Kinsley|    Young|     F| free|\n",
      "|     63|      Ayla|  Johnson|     F| free|\n",
      "|     37|    Jordan|    Hicks|     F| free|\n",
      "|      6|   Cecilia|    Owens|     F| free|\n",
      "|     15|      Lily|     Koch|     F| paid|\n",
      "|     27|    Carlos|   Carter|     M| free|\n",
      "|     89|   Kynnedi|  Sanchez|     F| free|\n",
      "|     57| Katherine|      Gay|     F| free|\n",
      "|     74|    Braden|   Parker|     M| free|\n",
      "|     29|Jacqueline|    Lynch|     F| paid|\n",
      "|     75|    Joseph|Gutierrez|     M| free|\n",
      "|     61|    Samuel| Gonzalez|     M| free|\n",
      "|     88|  Mohammad|Rodriguez|     M| free|\n",
      "|     64|    Hannah|  Calhoun|     F| free|\n",
      "|     15|      Lily|     Koch|     F| free|\n",
      "|     95|      Sara|  Johnson|     F| paid|\n",
      "+-------+----------+---------+------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-09-23 14:50:27,372 INFO  [etl] users_table count: 104\n"
     ]
    }
   ],
   "source": [
    "df_l.createOrReplaceTempView(\"log_view\")\n",
    "\n",
    "# extract columns for users table\n",
    "users_table = spark.sql(\"\"\"\n",
    "SELECT DISTINCT userId as user_id,\n",
    "                firstName as first_name,\n",
    "                lastName as last_name,\n",
    "                gender,\n",
    "                level\n",
    "FROM log_view\n",
    "\"\"\")\n",
    "users_table.printSchema()\n",
    "users_table.show()\n",
    "LOG.info(f\"users_table count: {users_table.count()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write users table to parquet files\n",
    "users_table.write.parquet(output_data+\"users.parquet\", mode = \"overwrite\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## time table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- artist: string (nullable = true)\n",
      " |-- auth: string (nullable = true)\n",
      " |-- firstName: string (nullable = true)\n",
      " |-- gender: string (nullable = true)\n",
      " |-- itemInSession: long (nullable = true)\n",
      " |-- lastName: string (nullable = true)\n",
      " |-- length: double (nullable = true)\n",
      " |-- level: string (nullable = true)\n",
      " |-- location: string (nullable = true)\n",
      " |-- method: string (nullable = true)\n",
      " |-- page: string (nullable = true)\n",
      " |-- registration: double (nullable = true)\n",
      " |-- sessionId: long (nullable = true)\n",
      " |-- song: string (nullable = true)\n",
      " |-- status: long (nullable = true)\n",
      " |-- ts: long (nullable = true)\n",
      " |-- userAgent: string (nullable = true)\n",
      " |-- userId: string (nullable = true)\n",
      " |-- timestamp: string (nullable = true)\n",
      " |-- datetime: string (nullable = true)\n",
      "\n",
      "+-----------+---------+---------+------+-------------+--------+---------+-----+--------------------+------+--------+-----------------+---------+--------------------+------+-------------+--------------------+------+-------------------+----------+\n",
      "|     artist|     auth|firstName|gender|itemInSession|lastName|   length|level|            location|method|    page|     registration|sessionId|                song|status|           ts|           userAgent|userId|          timestamp|  datetime|\n",
      "+-----------+---------+---------+------+-------------+--------+---------+-----+--------------------+------+--------+-----------------+---------+--------------------+------+-------------+--------------------+------+-------------------+----------+\n",
      "|   Harmonia|Logged In|     Ryan|     M|            0|   Smith|655.77751| free|San Jose-Sunnyval...|   PUT|NextSong|1.541016707796E12|      583|       Sehr kosmisch|   200|1542241826796|\"Mozilla/5.0 (X11...|    26|2018-11-14 16:30:26|2018-11-14|\n",
      "|The Prodigy|Logged In|     Ryan|     M|            1|   Smith|260.07465| free|San Jose-Sunnyval...|   PUT|NextSong|1.541016707796E12|      583|     The Big Gundown|   200|1542242481796|\"Mozilla/5.0 (X11...|    26|2018-11-14 16:41:21|2018-11-14|\n",
      "|      Train|Logged In|     Ryan|     M|            2|   Smith|205.45261| free|San Jose-Sunnyval...|   PUT|NextSong|1.541016707796E12|      583|            Marry Me|   200|1542242741796|\"Mozilla/5.0 (X11...|    26|2018-11-14 16:45:41|2018-11-14|\n",
      "|Sony Wonder|Logged In|   Samuel|     M|            0|Gonzalez|218.06975| free|Houston-The Woodl...|   PUT|NextSong|1.540492941796E12|      597|           Blackbird|   200|1542253449796|\"Mozilla/5.0 (Mac...|    61|2018-11-14 19:44:09|2018-11-14|\n",
      "|  Van Halen|Logged In|    Tegan|     F|            2|  Levine|289.38404| paid|Portland-South Po...|   PUT|NextSong|1.540794356796E12|      602|Best Of Both Worl...|   200|1542260935796|\"Mozilla/5.0 (Mac...|    80|2018-11-14 21:48:55|2018-11-14|\n",
      "+-----------+---------+---------+------+-------------+--------+---------+-----+--------------------+------+--------+-----------------+---------+--------------------+------+-------------+--------------------+------+-------------------+----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# create timestamp column from original timestamp column\n",
    "\n",
    "import pyspark.sql.functions as f\n",
    "from pyspark.sql.functions import udf\n",
    "from pyspark.sql import types as t\n",
    "from datetime import datetime\n",
    "from pyspark.sql.functions import to_timestamp\n",
    "\n",
    "# https://knowledge.udacity.com/questions/192909\n",
    "# create timestamp column from original timestamp column\n",
    "get_timestamp = udf(lambda x:  datetime.fromtimestamp(x/1000).strftime('%Y-%m-%d %H:%M:%S'))\n",
    "df_l = df_l.withColumn(\"timestamp\", get_timestamp(df_l.ts))\n",
    "    \n",
    "# create datetime column from original timestamp column\n",
    "get_datetime = udf(lambda x: datetime.fromtimestamp(x/1000).strftime('%Y-%m-%d'))\n",
    "df_l = df_l.withColumn(\"datetime\", get_datetime(df_l.ts))\n",
    "\n",
    "df_l.printSchema()\n",
    "df_l.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- start_time: string (nullable = true)\n",
      " |-- hour: integer (nullable = true)\n",
      " |-- day: integer (nullable = true)\n",
      " |-- week: integer (nullable = true)\n",
      " |-- month: integer (nullable = true)\n",
      " |-- year: integer (nullable = true)\n",
      " |-- weekday: integer (nullable = true)\n",
      "\n",
      "+-------------------+----+---+----+-----+----+-------+\n",
      "|         start_time|hour|day|week|month|year|weekday|\n",
      "+-------------------+----+---+----+-----+----+-------+\n",
      "|2018-11-14 22:14:16|  22| 14|  46|   11|2018|      4|\n",
      "|2018-11-15 12:38:46|  12| 15|  46|   11|2018|      5|\n",
      "|2018-11-15 14:48:46|  14| 15|  46|   11|2018|      5|\n",
      "|2018-11-14 01:19:37|   1| 14|  46|   11|2018|      4|\n",
      "|2018-11-13 10:42:47|  10| 13|  46|   11|2018|      3|\n",
      "+-------------------+----+---+----+-----+----+-------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# extract columns to create time table\n",
    "df_l.createOrReplaceTempView(\"log_view\")\n",
    "\n",
    "time_table = spark.sql(\"\"\"\n",
    "SELECT  DISTINCT timestamp AS start_time, \n",
    "                     hour(timestamp) AS hour, \n",
    "                     day(timestamp)  AS day, \n",
    "                     weekofyear(timestamp) AS week,\n",
    "                     month(timestamp) AS month,\n",
    "                     year(timestamp) AS year,\n",
    "                     dayofweek(timestamp) AS weekday\n",
    "FROM log_view\n",
    "\"\"\")\n",
    "\n",
    "time_table.printSchema()\n",
    "time_table.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write time table to parquet files partitioned by year and month\n",
    "time_table.write.partitionBy(\"year\", \"month\").parquet(output_data+\"time.parquet\", mode = \"overwrite\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## create fact table: songplays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- artist: string (nullable = true)\n",
      " |-- auth: string (nullable = true)\n",
      " |-- firstName: string (nullable = true)\n",
      " |-- gender: string (nullable = true)\n",
      " |-- itemInSession: long (nullable = true)\n",
      " |-- lastName: string (nullable = true)\n",
      " |-- length: double (nullable = true)\n",
      " |-- level: string (nullable = true)\n",
      " |-- location: string (nullable = true)\n",
      " |-- method: string (nullable = true)\n",
      " |-- page: string (nullable = true)\n",
      " |-- registration: double (nullable = true)\n",
      " |-- sessionId: long (nullable = true)\n",
      " |-- song: string (nullable = true)\n",
      " |-- status: long (nullable = true)\n",
      " |-- ts: long (nullable = true)\n",
      " |-- userAgent: string (nullable = true)\n",
      " |-- userId: string (nullable = true)\n",
      " |-- timestamp: string (nullable = true)\n",
      " |-- datetime: string (nullable = true)\n",
      "\n",
      "+-----------+---------+---------+------+-------------+--------+---------+-----+--------------------+------+--------+-----------------+---------+--------------------+------+-------------+--------------------+------+-------------------+----------+\n",
      "|     artist|     auth|firstName|gender|itemInSession|lastName|   length|level|            location|method|    page|     registration|sessionId|                song|status|           ts|           userAgent|userId|          timestamp|  datetime|\n",
      "+-----------+---------+---------+------+-------------+--------+---------+-----+--------------------+------+--------+-----------------+---------+--------------------+------+-------------+--------------------+------+-------------------+----------+\n",
      "|   Harmonia|Logged In|     Ryan|     M|            0|   Smith|655.77751| free|San Jose-Sunnyval...|   PUT|NextSong|1.541016707796E12|      583|       Sehr kosmisch|   200|1542241826796|\"Mozilla/5.0 (X11...|    26|2018-11-14 16:30:26|2018-11-14|\n",
      "|The Prodigy|Logged In|     Ryan|     M|            1|   Smith|260.07465| free|San Jose-Sunnyval...|   PUT|NextSong|1.541016707796E12|      583|     The Big Gundown|   200|1542242481796|\"Mozilla/5.0 (X11...|    26|2018-11-14 16:41:21|2018-11-14|\n",
      "|      Train|Logged In|     Ryan|     M|            2|   Smith|205.45261| free|San Jose-Sunnyval...|   PUT|NextSong|1.541016707796E12|      583|            Marry Me|   200|1542242741796|\"Mozilla/5.0 (X11...|    26|2018-11-14 16:45:41|2018-11-14|\n",
      "|Sony Wonder|Logged In|   Samuel|     M|            0|Gonzalez|218.06975| free|Houston-The Woodl...|   PUT|NextSong|1.540492941796E12|      597|           Blackbird|   200|1542253449796|\"Mozilla/5.0 (Mac...|    61|2018-11-14 19:44:09|2018-11-14|\n",
      "|  Van Halen|Logged In|    Tegan|     F|            2|  Levine|289.38404| paid|Portland-South Po...|   PUT|NextSong|1.540794356796E12|      602|Best Of Both Worl...|   200|1542260935796|\"Mozilla/5.0 (Mac...|    80|2018-11-14 21:48:55|2018-11-14|\n",
      "+-----------+---------+---------+------+-------------+--------+---------+-----+--------------------+------+--------+-----------------+---------+--------------------+------+-------------+--------------------+------+-------------------+----------+\n",
      "only showing top 5 rows\n",
      "\n",
      "root\n",
      " |-- artist_id: string (nullable = true)\n",
      " |-- artist_latitude: double (nullable = true)\n",
      " |-- artist_location: string (nullable = true)\n",
      " |-- artist_longitude: double (nullable = true)\n",
      " |-- artist_name: string (nullable = true)\n",
      " |-- duration: double (nullable = true)\n",
      " |-- num_songs: long (nullable = true)\n",
      " |-- song_id: string (nullable = true)\n",
      " |-- title: string (nullable = true)\n",
      " |-- year: long (nullable = true)\n",
      "\n",
      "+------------------+---------------+-----------------+----------------+--------------------+---------+---------+------------------+--------------------+----+\n",
      "|         artist_id|artist_latitude|  artist_location|artist_longitude|         artist_name| duration|num_songs|           song_id|               title|year|\n",
      "+------------------+---------------+-----------------+----------------+--------------------+---------+---------+------------------+--------------------+----+\n",
      "|ARDR4AC1187FB371A1|           null|                 |            null|Montserrat Caball...|511.16363|        1|SOBAYLL12A8C138AF9|Sono andati? Fing...|   0|\n",
      "|AREBBGV1187FB523D2|           null|      Houston, TX|            null|Mike Jones (Featu...|173.66159|        1|SOOLYAZ12A6701F4A6|Laws Patrolling (...|   0|\n",
      "|ARMAC4T1187FB3FA4C|       40.82624|Morris Plains, NJ|       -74.47995|The Dillinger Esc...|207.77751|        1|SOBBUGU12A8C13E95D|Setting Fire to S...|2004|\n",
      "|ARPBNLO1187FB3D52F|       40.71455|     New York, NY|       -74.00712|            Tiny Tim| 43.36281|        1|SOAOIBZ12AB01815BE|I Hold Your Hand ...|2000|\n",
      "|ARDNS031187B9924F0|       32.67828|          Georgia|       -83.22295|          Tim Wilson|186.48771|        1|SONYPOM12A8C13B2D7|I Think My Wife I...|2005|\n",
      "+------------------+---------------+-----------------+----------------+--------------------+---------+---------+------------------+--------------------+----+\n",
      "only showing top 5 rows\n",
      "\n",
      "root\n",
      " |-- start_time: string (nullable = true)\n",
      " |-- hour: integer (nullable = true)\n",
      " |-- day: integer (nullable = true)\n",
      " |-- week: integer (nullable = true)\n",
      " |-- month: integer (nullable = true)\n",
      " |-- year: integer (nullable = true)\n",
      " |-- weekday: integer (nullable = true)\n",
      "\n",
      "+-------------------+----+---+----+-----+----+-------+\n",
      "|         start_time|hour|day|week|month|year|weekday|\n",
      "+-------------------+----+---+----+-----+----+-------+\n",
      "|2018-11-14 22:14:16|  22| 14|  46|   11|2018|      4|\n",
      "|2018-11-15 12:38:46|  12| 15|  46|   11|2018|      5|\n",
      "|2018-11-15 14:48:46|  14| 15|  46|   11|2018|      5|\n",
      "|2018-11-14 01:19:37|   1| 14|  46|   11|2018|      4|\n",
      "|2018-11-13 10:42:47|  10| 13|  46|   11|2018|      3|\n",
      "+-------------------+----+---+----+-----+----+-------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# quick check before joining\n",
    "\n",
    "df_l.printSchema()\n",
    "df_l.show(5)\n",
    "\n",
    "df_s.printSchema()\n",
    "df_s.show(5)\n",
    "\n",
    "time_table.printSchema()\n",
    "time_table.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- songplay_id: long (nullable = false)\n",
      " |-- datetime: string (nullable = true)\n",
      " |-- user_id: string (nullable = true)\n",
      " |-- level: string (nullable = true)\n",
      " |-- song_id: string (nullable = true)\n",
      " |-- artist_id: string (nullable = true)\n",
      " |-- session_id: long (nullable = true)\n",
      " |-- location: string (nullable = true)\n",
      " |-- userAgent: string (nullable = true)\n",
      " |-- year: integer (nullable = true)\n",
      " |-- month: integer (nullable = true)\n",
      "\n",
      "+-----------+----------+-------+-----+------------------+------------------+----------+--------------------+--------------------+----+-----+\n",
      "|songplay_id|  datetime|user_id|level|           song_id|         artist_id|session_id|            location|           userAgent|year|month|\n",
      "+-----------+----------+-------+-----+------------------+------------------+----------+--------------------+--------------------+----+-----+\n",
      "|          0|2018-11-21|     15| paid|SOZCTXZ12AB0182364|AR5KOSW1187FB35FF4|       818|Chicago-Napervill...|\"Mozilla/5.0 (X11...|2018|   11|\n",
      "+-----------+----------+-------+-----+------------------+------------------+----------+--------------------+--------------------+----+-----+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-09-23 16:00:49,541 INFO  [etl] songplays table count: 1\n"
     ]
    }
   ],
   "source": [
    "# extract columns from joined song and log datasets to create songplays table\n",
    "from pyspark.sql.functions import monotonically_increasing_id\n",
    "df_l.createOrReplaceTempView(\"logs\")\n",
    "df_s.createOrReplaceTempView(\"songs\")\n",
    "time_table.createOrReplaceTempView(\"time\")\n",
    "\n",
    "songplays_table = spark.sql(\"\"\"\n",
    "SELECT\n",
    "    monotonically_increasing_id() as songplay_id,\n",
    "    l.datetime,\n",
    "    l.userId as user_id,\n",
    "    l.level,\n",
    "    s.song_id,\n",
    "    s.artist_id,\n",
    "    l.sessionId as session_id,\n",
    "    l.location,\n",
    "    l.userAgent,\n",
    "    t.year,\n",
    "    t.month\n",
    "FROM logs l\n",
    "JOIN songs s ON l.song = s.title AND l.artist = s.artist_name AND l.length = s.duration\n",
    "JOIN time t ON l.timestamp = t.start_time\n",
    "\"\"\")\n",
    "\n",
    "# df_sp = df_l.join(df_s, (df_l.artist == df_s.artist_name) & (df_l.song == df_s.title) & (df_l.length == df_s.duration))\n",
    "# df_sp = df_sp.join(time_table, (df_sp.datetime == time_table.start_time))\n",
    "\n",
    "# songplays_table = songplays_table.withColumn('songplay_id', )\n",
    "songplays_table.printSchema()\n",
    "songplays_table.show(5)\n",
    "LOG.info(f\"songplays table count: {songplays_table.count()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write songplays table to parquet files partitioned by year and month\n",
    "songplays_table.write.partitionBy(\"year\", \"month\").parquet(output_data+\"songplays.parquet\", mode = \"overwrite\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Query play"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- songplay_id: long (nullable = true)\n",
      " |-- datetime: string (nullable = true)\n",
      " |-- user_id: string (nullable = true)\n",
      " |-- level: string (nullable = true)\n",
      " |-- song_id: string (nullable = true)\n",
      " |-- artist_id: string (nullable = true)\n",
      " |-- session_id: long (nullable = true)\n",
      " |-- location: string (nullable = true)\n",
      " |-- userAgent: string (nullable = true)\n",
      "\n",
      "+------------+----------+-------+-----+------------------+------------------+----------+--------------------+--------------------+\n",
      "| songplay_id|  datetime|user_id|level|           song_id|         artist_id|session_id|            location|           userAgent|\n",
      "+------------+----------+-------+-----+------------------+------------------+----------+--------------------+--------------------+\n",
      "|274877906944|2018-11-15|     49| paid|SOLQSYZ12A58A7919B|ARQSM561187FB4A0CF|       621|San Francisco-Oak...|Mozilla/5.0 (Wind...|\n",
      "|274877906945|2018-11-14|     16| paid|SOYPWPS12AC4688650|ARCPYBD1187B9A56CE|       479|Birmingham-Hoover...|\"Mozilla/5.0 (Mac...|\n",
      "+------------+----------+-------+-----+------------------+------------------+----------+--------------------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Read songs_table\n",
    "# input_data_parquet = output_data + \"songplays.parquet\"\n",
    "real_songplays = \"songplays.parquet.emr-1st-try/year=2018/month=11/part-00032-d1e1f19c-ec3c-4dba-9d65-91062627bbfd.c000.snappy.parquet\"\n",
    "df = spark.read.parquet(real_songplays)\n",
    "df.printSchema()\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
